diff --git a/src/llama-model-loader.cpp b/src/llama-model-loader.cpp
index 1501e39..b878a71 100644
--- a/src/llama-model-loader.cpp
+++ b/src/llama-model-loader.cpp
@@ -267,7 +267,7 @@ namespace GGUFMeta {
 
         if (kid < 0) {
             if (required) {
-                throw std::runtime_error(format("key not found in model: %s", key.c_str()));
+                LLAMA_LOG_WARN("%s: key not found in model: %s - continuing\n", __func__, key.c_str()); return false;
             }
             return false;
         }
@@ -295,7 +295,7 @@ namespace GGUFMeta {
 
         if (kid < 0 || gguf_get_kv_type(ctx, kid) != GGUF_TYPE_ARRAY) {
             if (required) {
-                throw std::runtime_error(format("array key not found in model: %s", key.c_str()));
+                LLAMA_LOG_WARN("%s: array key not found in model: %s - continuing\n", __func__, key.c_str()); return false;
             }
             return false;
         }
@@ -336,7 +336,7 @@ namespace GGUFMeta {
 
         if (kid < 0 || gguf_get_kv_type(ctx, kid) != GGUF_TYPE_ARRAY) {
             if (required) {
-                throw std::runtime_error(format("array key not found in model: %s", key.c_str()));
+                LLAMA_LOG_WARN("%s: array key not found in model: %s - continuing\n", __func__, key.c_str()); return false;
             }
             return false;
         }
@@ -396,7 +396,12 @@ namespace GGUFMeta {
         const bool found = GGUFMeta::GKV<T>::set(meta.get(), key, result, override);
 
         if (required && !found) {
-            throw std::runtime_error(format("key not found in model: %s", key.c_str()));
+            // Tolerant behavior: do not throw when a required key is missing.
+            // Assign a default value and continue so non-LLM GGUFs (e.g. image models)
+            // can still be loaded for tensor-only operations such as quantization.
+            LLAMA_LOG_WARN("%s: key not found in model: %s - assigning default and continuing\n", __func__, key.c_str());
+            result = T{}; // zero-initialize (0, 0.0, empty string, etc.)
+            return false;
         }
 
         return found;
@@ -431,7 +436,7 @@ namespace GGUFMeta {
 
         if (kid < 0) {
             if (required) {
-                throw std::runtime_error(format("key not found in model: %s", key.c_str()));
+                LLAMA_LOG_WARN("%s: key not found in model: %s - continuing\n", __func__, key.c_str()); return false;
             }
             return false;
         }
@@ -477,7 +482,8 @@ namespace GGUFMeta {
 
         if (id < 0) {
             if (required) {
-                throw std::runtime_error(format("key not found in model: %s", key.c_str()));
+                LLAMA_LOG_WARN("%s: key not found in model: %s - continuing\n", __func__, key.c_str());
+                return false;
             }
             return false;
         }
@@ -539,18 +545,12 @@ llama_model_loader::llama_model_loader(
     files.emplace_back(new llama_file(fname.c_str(), "rb", use_direct_io));
     contexts.emplace_back(ctx);
 
-    if (use_mmap && use_direct_io) {
-        if (files.back()->has_direct_io()) {
-            LLAMA_LOG_WARN("%s: direct I/O is enabled, disabling mmap\n", __func__);
-            use_mmap = false;
-        } else {
-            LLAMA_LOG_WARN("%s: direct I/O is not available, using mmap\n", __func__);
-            use_direct_io = false;
+    use_direct_io = use_direct_io && files.back()->has_direct_io();
 
-            // reopen file using std::fopen for mmap
-            files.pop_back();
-            files.emplace_back(new llama_file(fname.c_str(), "rb", false));
-        }
+    // Disable mmap in case Direct I/O is enabled and available
+    if (use_direct_io && use_mmap) {
+        use_mmap = false;
+        LLAMA_LOG_WARN("%s: direct I/O is enabled, disabling mmap\n", __func__);
     }
 
     // Save tensors data offset of the main file.
@@ -1259,3 +1259,4 @@ void llama_model_loader::print_info() const {
         LLAMA_LOG_INFO("%s: file size   = %.2f GiB (%.2f BPW) \n", __func__, n_bytes/1024.0/1024.0/1024.0, n_bytes*8.0/n_elements);
     }
 }
+
