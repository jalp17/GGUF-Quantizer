diff --git a/src/llama-model.cpp b/src/llama-model.cpp
index 72490a89b..07acfb083 100644
--- a/src/llama-model.cpp
+++ b/src/llama-model.cpp
@@ -483,7 +483,8 @@ void llama_model::load_stats(llama_model_loader & ml) {
 void llama_model::load_arch(llama_model_loader & ml) {
     arch = ml.get_arch();
     if (arch == LLM_ARCH_UNKNOWN) {
-        throw std::runtime_error("unknown model architecture: '" + ml.get_arch_name() + "'");
+        // Allow unknown architectures (image models like SDXL, SD1, Flux)
+        LLAMA_LOG_WARN("%s: unknown architecture '%s' - proceeding in tolerant mode\n", __func__, ml.get_arch_name().c_str());
     }
 }
 
@@ -505,8 +506,16 @@ void llama_model::load_hparams(llama_model_loader & ml) {
     ml.get_key(LLM_KV_GENERAL_NAME, name, false);
 
     // everything past this point is not vocab-related
-    // for CLIP models, we only need to load tensors, no hparams
-    if (hparams.vocab_only || ml.get_arch() == LLM_ARCH_CLIP) {
+    // for CLIP and image diffusion models, we only need to load tensors, no hparams
+    if (hparams.vocab_only || ml.get_arch() == LLM_ARCH_CLIP
+            || arch == LLM_ARCH_UNKNOWN
+            || arch == LLM_ARCH_SDXL
+            || arch == LLM_ARCH_SD1
+            || arch == LLM_ARCH_SD3
+            || arch == LLM_ARCH_FLUX
+            || arch == LLM_ARCH_AURORA
+            || arch == LLM_ARCH_LTXV
+            || arch == LLM_ARCH_LUMINA) {
         return;
     }
 
@@ -2450,7 +2459,9 @@ void llama_model::load_hparams(llama_model_loader & ml) {
                     default: type = LLM_TYPE_UNKNOWN;
                 }
             } break;
-        default: throw std::runtime_error("unsupported model architecture");
+        default:
+            LLAMA_LOG_WARN("%s: unsupported model architecture for hparams - skipping\n", __func__);
+            break;
     }
 
     pimpl->n_bytes = ml.n_bytes;
